{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9ded6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "434f5063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  1 01:23:45 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 581.80                 Driver Version: 581.80         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   52C    P5              6W /   60W |     993MiB /   6141MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2932    C+G   ...al\\Programs\\cursor\\Cursor.exe      N/A      |\n",
      "|    0   N/A  N/A            3348    C+G   ...n1h2txyewy\\CHXSmartScreen.exe      N/A      |\n",
      "|    0   N/A  N/A            4996    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            9492    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           10532    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A           10572    C+G   ...enterService\\DesktopParts.exe      N/A      |\n",
      "|    0   N/A  N/A           10676    C+G   ...enterService\\FloatingMenu.exe      N/A      |\n",
      "|    0   N/A  N/A           11116    C+G   ...ows\\System32\\NahimicSvc64.exe      N/A      |\n",
      "|    0   N/A  N/A           12088    C+G   ...1g1gvanyjgm\\WhatsApp.Root.exe      N/A      |\n",
      "|    0   N/A  N/A           12204    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13220    C+G   ...em32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13556    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           13564    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           17500    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           17800    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           18664    C+G   ...4__w2gh52qy24etm\\Nahimic3.exe      N/A      |\n",
      "|    0   N/A  N/A           19364    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A           20432    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           23236    C+G   ...26wp6bftszj\\TranslucentTB.exe      N/A      |\n",
      "|    0   N/A  N/A           24012    C+G   ....0.3650.96\\msedgewebview2.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c2b6747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# gpu configuration failed locally, so using cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40301c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python uses pillow to operate on images\n",
    "# convert images to tensors before itself\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2c1109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data already available in torchvision as splits\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "val_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1acca789",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "batch_size = 64\n",
    "num_channels = 1 #black and white image so 1\n",
    "img_size = 28 #28x28 each mnist image\n",
    "patch_size = 7 #paper it was 16, but as here already image size is small, so 7\n",
    "num_patches = (img_size // patch_size) ** 2\n",
    "embedding_dim = 64\n",
    "attention_heads = 4\n",
    "transformer_blocks = 4\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "mlp_hidden_nodes = 128 #2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "396800b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(num_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92d0308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as dataloader\n",
    "train_loader = dataloader.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  \n",
    "val_loader = dataloader.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58c80e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71d72471",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1,64,4,4\n",
    "        self.patch_embed = nn.Conv2d(num_channels, embedding_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # patch -> flatten\n",
    "        x = self.patch_embed(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d900c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(embedding_dim)\n",
    "        # batch first is true because we want the input to be in the shape of (batch_size, sequence_length, embedding_dim) else accuracy worsens\n",
    "        self.multihead_attention = nn.MultiheadAttention(embedding_dim, attention_heads, batch_first=True)\n",
    "        # embed -> hiddenlayer -> original form (mlp)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, mlp_hidden_nodes),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(mlp_hidden_nodes, embedding_dim),\n",
    "        )\n",
    "\n",
    "        # residual connections\n",
    "    def forward(self, x):\n",
    "        residual1 = x\n",
    "        x = self.layer_norm1(x)\n",
    "        # thrice to make x key,value,query\n",
    "        x = self.multihead_attention(x, x, x)[0]\n",
    "        x = x + residual1\n",
    "        residual2 = x\n",
    "        x = self.layer_norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = x + residual2\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "edea0316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP HEAD (after transformer encoder in the architecture)\n",
    "class MLPHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
    "        self.mlp_head = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm1(x)\n",
    "        x = self.mlp_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43232ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.patch_embedding = PatchEmbedding()\n",
    "        # cls token -> pos embedding ->cls token passed to mlp head\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embedding_dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, embedding_dim))\n",
    "        self.transformer_blocks = nn.Sequential(*[TransformerEncoder() for _ in range(transformer_blocks)]) #will be 4\n",
    "        self.mlp_head = MLPHead()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embedding(x)\n",
    "        #classtoken for every patch, so we expand\n",
    "        class_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat([class_token, x], dim=1)\n",
    "        x = x + self.pos_embedding\n",
    "        x = self.transformer_blocks(x)\n",
    "        # only class token is passed to mlp head\n",
    "        x = self.mlp_head(x[:, 0])\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abd3e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dc7a903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Batch 0/938 - Loss: 2.5629 - Accuracy: 3.12%\n",
      "Batch 100/938 - Loss: 0.5765 - Accuracy: 82.81%\n",
      "Batch 200/938 - Loss: 0.3744 - Accuracy: 87.50%\n",
      "Batch 300/938 - Loss: 0.1495 - Accuracy: 95.31%\n",
      "Batch 400/938 - Loss: 0.2234 - Accuracy: 89.06%\n",
      "Batch 500/938 - Loss: 0.2351 - Accuracy: 93.75%\n",
      "Batch 600/938 - Loss: 0.4059 - Accuracy: 90.62%\n",
      "Batch 700/938 - Loss: 0.1922 - Accuracy: 92.19%\n",
      "Batch 800/938 - Loss: 0.2358 - Accuracy: 93.75%\n",
      "Batch 900/938 - Loss: 0.1541 - Accuracy: 96.88%\n",
      "epoch 1 summary: loss 367.8988 accuracy 87.52%\n",
      "Epoch 2/5\n",
      "Batch 0/938 - Loss: 0.1123 - Accuracy: 98.44%\n",
      "Batch 100/938 - Loss: 0.1460 - Accuracy: 95.31%\n",
      "Batch 200/938 - Loss: 0.1005 - Accuracy: 95.31%\n",
      "Batch 300/938 - Loss: 0.0397 - Accuracy: 98.44%\n",
      "Batch 400/938 - Loss: 0.1431 - Accuracy: 95.31%\n",
      "Batch 500/938 - Loss: 0.0222 - Accuracy: 100.00%\n",
      "Batch 600/938 - Loss: 0.1010 - Accuracy: 95.31%\n",
      "Batch 700/938 - Loss: 0.2170 - Accuracy: 95.31%\n",
      "Batch 800/938 - Loss: 0.0198 - Accuracy: 100.00%\n",
      "Batch 900/938 - Loss: 0.0347 - Accuracy: 98.44%\n",
      "epoch 2 summary: loss 119.1400 accuracy 96.11%\n",
      "Epoch 3/5\n",
      "Batch 0/938 - Loss: 0.1209 - Accuracy: 96.88%\n",
      "Batch 100/938 - Loss: 0.0408 - Accuracy: 98.44%\n",
      "Batch 200/938 - Loss: 0.0494 - Accuracy: 100.00%\n",
      "Batch 300/938 - Loss: 0.0548 - Accuracy: 98.44%\n",
      "Batch 400/938 - Loss: 0.0527 - Accuracy: 96.88%\n",
      "Batch 500/938 - Loss: 0.1279 - Accuracy: 95.31%\n",
      "Batch 600/938 - Loss: 0.1663 - Accuracy: 95.31%\n",
      "Batch 700/938 - Loss: 0.1789 - Accuracy: 93.75%\n",
      "Batch 800/938 - Loss: 0.0430 - Accuracy: 96.88%\n",
      "Batch 900/938 - Loss: 0.0899 - Accuracy: 96.88%\n",
      "epoch 3 summary: loss 88.6328 accuracy 97.11%\n",
      "Epoch 4/5\n",
      "Batch 0/938 - Loss: 0.0125 - Accuracy: 100.00%\n",
      "Batch 100/938 - Loss: 0.0811 - Accuracy: 96.88%\n",
      "Batch 200/938 - Loss: 0.0264 - Accuracy: 100.00%\n",
      "Batch 300/938 - Loss: 0.1129 - Accuracy: 96.88%\n",
      "Batch 400/938 - Loss: 0.0985 - Accuracy: 95.31%\n",
      "Batch 500/938 - Loss: 0.1020 - Accuracy: 95.31%\n",
      "Batch 600/938 - Loss: 0.0324 - Accuracy: 98.44%\n",
      "Batch 700/938 - Loss: 0.0614 - Accuracy: 98.44%\n",
      "Batch 800/938 - Loss: 0.0401 - Accuracy: 98.44%\n",
      "Batch 900/938 - Loss: 0.0228 - Accuracy: 100.00%\n",
      "epoch 4 summary: loss 70.9344 accuracy 97.51%\n",
      "Epoch 5/5\n",
      "Batch 0/938 - Loss: 0.0484 - Accuracy: 98.44%\n",
      "Batch 100/938 - Loss: 0.0574 - Accuracy: 98.44%\n",
      "Batch 200/938 - Loss: 0.0361 - Accuracy: 98.44%\n",
      "Batch 300/938 - Loss: 0.0298 - Accuracy: 98.44%\n",
      "Batch 400/938 - Loss: 0.0030 - Accuracy: 100.00%\n",
      "Batch 500/938 - Loss: 0.0722 - Accuracy: 96.88%\n",
      "Batch 600/938 - Loss: 0.0055 - Accuracy: 100.00%\n",
      "Batch 700/938 - Loss: 0.1867 - Accuracy: 93.75%\n",
      "Batch 800/938 - Loss: 0.0237 - Accuracy: 100.00%\n",
      "Batch 900/938 - Loss: 0.0258 - Accuracy: 98.44%\n",
      "epoch 5 summary: loss 59.1948 accuracy 98.02%\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_epoch = 0\n",
    "    total_epoch = 0\n",
    "    print(f'Epoch {epoch+1}/{epochs}')\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct = (preds == labels).sum().item()\n",
    "        accuracy = 100.0 * correct / labels.size(0)\n",
    "        correct_epoch += correct\n",
    "        total_epoch += labels.size(0)\n",
    "\n",
    "        if (batch_idx) % 100 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(train_loader)} - Loss: {loss.item():.4f} - Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    epoch_accuracy = 100.0 * correct_epoch / total_epoch\n",
    "    print(f'epoch {epoch+1} summary: loss {total_loss:.4f} accuracy {epoch_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "243f9ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.25%\n"
     ]
    }
   ],
   "source": [
    "# validation loop\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_accuracy = 100.0 * correct / total\n",
    "print(f'Test accuracy: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropout not used, also mlp expansion is 2x and not 4x in this implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8bcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e4c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17cdfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ecd94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723479cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a03ee9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29cf4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12517043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da807c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f7415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18002a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbed65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcff113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05646eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac6d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b21bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5673560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e069078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682da63c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a717540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f959745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0753361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314a745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388eb7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9587e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876fc67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe9c7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dab2b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e43c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c2e17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fde0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4a370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81e7a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2aa490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf1749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409cb32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dd334d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
